{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Outliers"
      ],
      "metadata": {
        "id": "eC6ng4CX-ZMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Outlier é uma observação que está numericamente distante do restante dos dados ou, em palavras simples, é o valor que está fora da faixa.\"\n",
        "</p>\n",
        "Referencias dados: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data"
      ],
      "metadata": {
        "id": "Q6a1c4OCvEVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<style>\n",
        "  table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 8px;\n",
        "    text-align: left;\n",
        "    border-bottom: 1px solid #ddd;\n",
        "  }\n",
        "  th {\n",
        "    background-color: #f2f2f2;\n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Método de Detecção de Outliers</th>\n",
        "      <th>Quando Usar</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td><strong>Métodos Hipotetico</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Teste G - de Grubbs</td>\n",
        "      <td>Útil quando se deseja determinar se existe pelo menos um valor discrepante (outlier) em uma amostra de dados.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Métodos de Visualização</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Boxplot</td>\n",
        "      <td>Útil para identificar visualmente a presença de outliers e sua distribuição.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Scatter Plot</td>\n",
        "      <td>Permite visualizar a dispersão dos dados e identificar pontos que se distanciam significativamente da tendência geral.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Métodos Estatísticos</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Z-Score</td>\n",
        "      <td>Útil quando os dados seguem uma distribuição normal ou aproximadamente normal.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Intervalo Interquartil (IQR)</td>\n",
        "      <td>Recomendado quando os dados possuem uma distribuição não normal ou com muitos outliers.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Método de pré-processamento de dados</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "      <td>Percentile Capping</td>\n",
        "      <td>Utilizado em conjunto com métodos de detecção de outliers para lidar com os valores identificados como extremos..</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Métodos Baseados em Distância</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "      <td>Distância Mahalanobis</td>\n",
        "      <td>Útil quando há correlação entre as variáveis e é importante levar em consideração essa correlação.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Distância Euclidiana</td>\n",
        "      <td>Adequado quando não há necessidade de considerar a correlação entre as variáveis.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Métodos de Agrupamento</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>DBSCAN</td>\n",
        "      <td>Indicado quando os dados são distribuídos em grupos e os outliers estão em regiões de baixa densidade.</td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "      <td><strong>Métodos de Machine Learning</strong></td>\n",
        "      <td></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Isolation Forest</td>\n",
        "      <td>Útil quando os dados possuem uma alta dimensionalidade e não seguem uma distribuição específica.</td>\n",
        "    </tr>\n",
        "\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "WBkDxkGcv7f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "vfIBhs06v3V4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TLf-Oc7s-eC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Abrindo os dados\n",
        "df = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "8AS3KlZu_qcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separando os valores que eu quero\n",
        "df_subset = df[['LotArea', 'SalePrice']].copy() # Usamos .copy() para garantir que estamos operando em um novo DataFrame\n",
        "#Criando uma nova coluna\n",
        "Valores = df['SalePrice'] / df['LotArea']"
      ],
      "metadata": {
        "id": "z0cxEvxf_2bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hypothesis Testing (Teste G -  de Grubbs)\n"
      ],
      "metadata": {
        "id": "2xPWaLybCwwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "def grubbs_test(x):\n",
        "    n = len(x)\n",
        "    mean_x = np.mean(x)\n",
        "    sd_x = np.std(x)\n",
        "    numerator = max(abs(x-mean_x))\n",
        "    g_calculated = numerator/sd_x\n",
        "    print(\"Grubbs Calculated Value:\",g_calculated)\n",
        "    t_value = stats.t.ppf(1 - 0.05 / (2 * n), n - 2)\n",
        "    g_critical = ((n - 1) * np.sqrt(np.square(t_value))) / (np.sqrt(n) * np.sqrt(n - 2 + np.square(t_value)))\n",
        "    print(\"Grubbs Critical Value:\",g_critical)\n",
        "    if g_critical > g_calculated:\n",
        "      print('Não tem outlier')\n",
        "      print(\"A partir do teste de grubbs, observamos que o valor calculado é menor que o valor crítico. Aceitamos a hipótese nula e concluímos que não há valores atípicos.\\n\")\n",
        "    else:\n",
        "      print('Tem outlier')\n",
        "      print(\"Do teste de grubbs, observamos que o valor calculado é maior que o valor crítico. Rejeitamos a hipótese nula e concluímos que há um valor atípico.\\n\")\n",
        "\n",
        "grubbs_test(Valores)"
      ],
      "metadata": {
        "id": "U9juxufzB1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Métodos de Visualização"
      ],
      "metadata": {
        "id": "JF4G3YSDBcWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boxplot"
      ],
      "metadata": {
        "id": "-3OPCK2EBkGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Plot = pd.DataFrame(Valores,columns=['Valores'])\n",
        "\n",
        "# Gerar o boxplot\n",
        "plt.figure(figsize=(4, 3))\n",
        "Plot.boxplot(column=['Valores'],flierprops=dict(marker='s', markerfacecolor='red', markersize=2))\n",
        "plt.title('Boxplot da Valores')\n",
        "plt.ylabel('Valores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWhQfd_jBpsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scatter Plot"
      ],
      "metadata": {
        "id": "3ziSPr5pBp8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Plot = pd.DataFrame(Valores,columns=['Valores'])\n",
        "\n",
        "# Calcular os quartis\n",
        "Q1 = Plot['Valores'].quantile(0.25)\n",
        "Q3 = Plot['Valores'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identificar os outliers\n",
        "outliers = Plot[(Plot['Valores'] < (Q1 - 1.5 * IQR)) | (Plot['Valores'] > (Q3 + 1.5 * IQR))]\n",
        "\n",
        "# Gerar o scatter plot\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.scatter(df.index, Plot['Valores'], label='Dados')\n",
        "plt.scatter(outliers.index, outliers['Valores'], color='red', label='Outliers')\n",
        "plt.title('Scatter Plot da Valores')\n",
        "plt.xlabel('Índice')\n",
        "plt.ylabel('Valores')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D5o2V53fBsWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mahalanobis Distance"
      ],
      "metadata": {
        "id": "kMFYr0te0Vb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import mahalanobis\n",
        "\n",
        "# Calculando a média para cada coluna\n",
        "means = Valores.mean()\n",
        "\n",
        "# Calculando a matriz de covariância (neste caso, é apenas a variância)\n",
        "variance = np.var(Valores)\n",
        "\n",
        "# Ponto de referência (pode ser a média ou qualquer outro ponto de interesse)\n",
        "reference_point = means\n",
        "\n",
        "# Calculando a distância de Mahalanobis para cada ponto em relação ao ponto de referência\n",
        "distances = [mahalanobis([point], [reference_point], 1/variance) for point in Valores]\n",
        "\n",
        "#Criando o df\n",
        "distances_df = pd.DataFrame(distances, columns=['Distances'])\n",
        "distances_df['Valores'] = Valores\n",
        "\n",
        "# Definindo um limite para as distâncias de Mahalanobis\n",
        "limite = 3  # Você pode ajustar este valor conforme necessário\n",
        "\n",
        "# Removendo os pontos que estão além do limite de distância de Mahalanobis\n",
        "df_sem_outliers = distances_df[np.array(distances) < limite]\n",
        "outliers = distances_df[np.array(distances) >= limite]\n",
        "\n",
        "print('Antes', distances_df['Valores'].count(),'Depois', df_sem_outliers['Valores'].size, 'Outliers:', outliers['Valores'].size)\n"
      ],
      "metadata": {
        "id": "MVR40rtg1et8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reference_point"
      ],
      "metadata": {
        "id": "-qUbNSYs-vSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Média (Centro de Massa):** Este é o ponto mais comum de referência. Usar a média como ponto de referência é útil quando você deseja calcular a distância de cada ponto de dados em relação ao centro médio de todo o conjunto de dados.\n",
        "    ```python\n",
        "    means = Valores.mean()\n",
        "    reference_point = means\n",
        "    ```\n",
        "\n",
        "- **Mediana:** Em alguns casos, pode ser mais apropriado usar a mediana como ponto de referência, especialmente se seus dados forem assimétricos ou contiverem outliers.\n",
        "    ```python\n",
        "    median = np.median(Valores)\n",
        "    reference_point = median\n",
        "    ```\n",
        "\n",
        "- **Moda:** Se você estiver lidando com dados categóricos, a moda (valor mais comum) pode ser uma escolha adequada para o ponto de referência.\n",
        "    ```python\n",
        "    mode = scipy.stats.mode(Valores)[0][0]\n",
        "    reference_point= mode\n",
        "    ```\n",
        "\n",
        "- **Ponto Arbitrário de Interesse:** Dependendo do seu problema, você também pode escolher um ponto específico de interesse como o ponto de referência. Isso pode ser útil em situações onde você tem um ponto específico que deseja usar como referência para calcular as distâncias.\n",
        "    ```python\n",
        "    interest_point = 10\n",
        "    reference_point = interest_point\n",
        "    ```\n"
      ],
      "metadata": {
        "id": "6pl40L4g-rQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Z-score"
      ],
      "metadata": {
        "id": "Wwxpi_M4C1eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores = zscore(Valores)\n",
        "\n",
        "z_scores_df = pd.DataFrame(z_scores,columns=['zscores'])\n",
        "\n",
        "z_scores_df['Valores'] = Valores\n",
        "\n",
        "limite_z = 3\n",
        "\n",
        "# Filtrar os valores onde 'zscore' é maior que o limite_z\n",
        "df_sem_outliers = z_scores_df.loc[z_scores_df['zscores'] < limite_z]\n",
        "\n",
        "Outliers = z_scores_df.loc[z_scores_df['zscores'] >= limite_z]\n",
        "\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers['Valores'].count(), 'Outliers:', Outliers['Valores'].count())\n"
      ],
      "metadata": {
        "id": "phOLh5m4BbSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Robust Zscore"
      ],
      "metadata": {
        "id": "M8JTrqShNvYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Inicializar o scaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Transformar os dados em uma matriz 2D\n",
        "dados_2d = Valores.values.reshape(-1, 1)\n",
        "\n",
        "# Aplicar o RobustScaler\n",
        "robust_scaled_data = scaler.fit_transform(dados_2d)\n",
        "\n",
        "# Criar um DataFrame com os dados escalados\n",
        "robust_scaled_df = pd.DataFrame(robust_scaled_data, columns=['Score'])\n",
        "\n",
        "robust_scaled_df['PricePerArea'] = Valores\n",
        "\n",
        "limite_z = 3\n",
        "\n",
        "# Filtrar os valores onde 'zscore' é maior que o limite_z\n",
        "df_sem_outliers = robust_scaled_df.loc[robust_scaled_df['Score'] < limite_z]\n",
        "\n",
        "Outliers = robust_scaled_df.loc[robust_scaled_df['Score'] >= limite_z]\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers['PricePerArea'].count(), 'Outliers:', Outliers['PricePerArea'].count())\n"
      ],
      "metadata": {
        "id": "Rykk3tz3Nzi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I.Q.R method"
      ],
      "metadata": {
        "id": "LEHn0BBiPvnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular Q1, Q3 e IQR\n",
        "Q1 = np.percentile(Valores, 25)\n",
        "Q3 = np.percentile(Valores, 75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identificar outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtrar os valores onde 'Valores' estão fora dos bounds\n",
        "df_sem_outliers = Valores[(Valores > lower_bound) & (Valores < upper_bound)]  # & = and\n",
        "outliers = Valores[(Valores < lower_bound) | (Valores > upper_bound)]  # | = OR\n",
        "\n",
        "print(\"Q1:\", Q1)\n",
        "print(\"Q3:\", Q3)\n",
        "print(\"IQR:\", IQR)\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers.count(), 'Outliers:', outliers.count())\n",
        "\n",
        "#print(\"Outliers:\", outliers)"
      ],
      "metadata": {
        "id": "-vxpqpN0Pu1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Winsorization method(Percentile Capping)"
      ],
      "metadata": {
        "id": "u8M82rHVUFYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir percentis para winsorização (5%)\n",
        "lower_percentile = 5\n",
        "upper_percentile = 95\n",
        "\n",
        "# Calcular os percentis\n",
        "lower_limit = np.percentile(Valores, lower_percentile)\n",
        "upper_limit = np.percentile(Valores, upper_percentile)\n",
        "\n",
        "# Winsorizar os dados\n",
        "# Identificar os índices dos valores dentro do intervalo desejado\n",
        "indices_dentro_intervalo = (Valores >= lower_limit) & (Valores <= upper_limit)\n",
        "indices_fora_intervalo = (Valores < lower_limit) | (Valores > upper_limit)\n",
        "\n",
        "\n",
        "# Criar um novo array contendo apenas os valores dentro do intervalo\n",
        "data_winsorized = Valores[indices_dentro_intervalo]\n",
        "outliers = Valores[indices_fora_intervalo]\n",
        "\n",
        "data_winsorized2 = pd.DataFrame(data_winsorized, columns=['Valores'])\n",
        "\n",
        "print(\"lower_limit:\", lower_limit)\n",
        "print(\"upper_percentile:\", upper_limit)\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', data_winsorized.size, 'Outliers:', outliers.size)\n"
      ],
      "metadata": {
        "id": "3mdknSU9SLpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Métodos Baseados em Distância"
      ],
      "metadata": {
        "id": "r06ulFps1Lqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Diferença entre Euclidean e Mahalanobis"
      ],
      "metadata": {
        "id": "kHZB1Yrd1blE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "A <b>distância euclidiana</b> é uma medida de distância padrão que trata todas as dimensões igualmente.\n",
        "<p>\n",
        "A <b>distância de Mahalanobis</b> leva em consideração a covariância entre as dimensões dos dados e normaliza as diferenças entre as variáveis pela variabilidade dos dados em cada direção"
      ],
      "metadata": {
        "id": "TcnpOqFtAeoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<style>\n",
        "  .center {\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "  }\n",
        "  img {\n",
        "    max-width: 20%; /* Define o tamanho máximo da imagem como 50% da largura do seu contêiner */\n",
        "    height: auto; /* Mantém a proporção da imagem */\n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*KzsugPQU-BTjvDACXbu9qw.jpeg\" alt=\"Imagem\">\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "hOxJbXtY0d_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Euclidean Distance"
      ],
      "metadata": {
        "id": "mjoRo78Y1Pn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando a média para cada coluna\n",
        "means = Valores.mean()\n",
        "\n",
        "# Calculando a distância euclidiana de cada ponto em relação à média\n",
        "distances = np.abs(Valores - means)\n",
        "\n",
        "distances_df = pd.DataFrame(distances, columns=['Distances'])\n",
        "\n",
        "distances_df['Valores'] = Valores\n",
        "\n",
        "# Definindo um limite para as distâncias euclidianas\n",
        "limite = 3  # Você pode ajustar este valor conforme necessário\n",
        "\n",
        "# Removendo os outliers\n",
        "df_sem_outliers = distances_df[distances > limite]\n",
        "outliers = distances_df[distances < limite]\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers['Valores'].size, 'Outliers:', outliers['Valores'].size)\n"
      ],
      "metadata": {
        "id": "LBQt2qqF1f4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Metodos Menos utilizados"
      ],
      "metadata": {
        "id": "hUp51pWGxTx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DBSCAN Clustering"
      ],
      "metadata": {
        "id": "RqXZ4CDEB1CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<body>\n",
        "  <h1>DBSCAN: Density-Based Spatial Clustering of Applications with Noise</h1>\n",
        "  <p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo de clustering muito popular usado em mineração de dados e análise de dados espaciais. Ele é projetado para identificar agrupamentos em conjuntos de dados baseados na densidade dos pontos.</p>\n",
        "\n",
        "  <p>A ideia central por trás do DBSCAN é agrupar pontos que estejam próximos uns dos outros em regiões densas, separadas por regiões mais vazias ou ruído. O algoritmo não requer especificação prévia do número de clusters e é capaz de lidar com diferentes formas e tamanhos de clusters.</p>\n",
        "\n",
        "  <p>O funcionamento do DBSCAN é baseado em dois parâmetros principais: o raio ε (epsilon) e o número mínimo de pontos (MinPts). O algoritmo começa selecionando um ponto aleatório e verifica quantos pontos estão dentro de uma distância ε dele. Se o número de pontos dentro desse raio for maior ou igual a MinPts, o ponto é considerado parte de um cluster e o processo se expande para os pontos vizinhos. Caso contrário, o ponto é marcado como ruído ou outlier.</p>\n",
        "\n",
        "  <p>DBSCAN tem várias vantagens, incluindo sua capacidade de lidar com clusters de diferentes formas e tamanhos, sua robustez à presença de ruído e sua eficiência computacional. No entanto, ele pode não ser adequado para conjuntos de dados de alta dimensionalidade devido ao \"problema da maldição da dimensionalidade\".</p>\n",
        "\n",
        "  <p>Em resumo, DBSCAN é um algoritmo de clustering que agrupa pontos com base na densidade, identificando regiões densas no espaço de características e separando-as do ruído e dos outliers. Ele é uma ferramenta poderosa para análise exploratória de dados e descoberta de padrões em conjuntos de dados complexos.</p>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "_Ppz2jI9IILw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<style>\n",
        "  .center {\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "  }\n",
        "  img {\n",
        "    max-width: 50%; /* Define o tamanho máximo da imagem como 50% da largura do seu contêiner */\n",
        "    height: auto; /* Mantém a proporção da imagem */\n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*t4QjgJ0JfDq9_VNGDNcj5w.png\" alt=\"DBSCAN \">\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "y3BOWazfHlSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Dando reshape para os dados ficarem 2d, caso necessario\n",
        "#dados_2d = Valores.values.reshape(-1, 1)\n",
        "\n",
        "# Padronizar os dados\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(df_subset)\n",
        "\n",
        "# Criar o modelo DBSCAN\n",
        "#Eps é o tamanho do raio do circulo\n",
        "#min_sample é q quantidade de pontos que devem ter dentro do circulo\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "\n",
        "# Ajustar o modelo aos dados\n",
        "dbscan.fit(data_scaled)\n",
        "\n",
        "# Adicionar rótulos de cluster ao DataFrame original\n",
        "df_subset['cluster'] = dbscan.labels_\n",
        "\n",
        "# Número de clusters no resultado, ignorando o ruído se estiver presente.\n",
        "n_clusters_ = len(set(df_subset)) - (1 if -1 in df_subset else 0)\n",
        "n_noise_ = list(df_subset).count(-1)\n",
        "\n",
        "outliers = df_subset[df_subset['cluster'] == -1]\n",
        "df_sem_outliers = df_subset[df_subset['cluster'] == 0]\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers['SalePrice'].size, 'Outliers:', outliers['SalePrice'].size)\n",
        "\n",
        "print('Número estimado de clusters: %d' % n_clusters_)\n",
        "print('Número estimado de pontos de ruído: %d' % n_noise_)"
      ],
      "metadata": {
        "id": "1F3Q9YSuGo7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Isolation Forest\n",
        "Esse modo é bem ruim."
      ],
      "metadata": {
        "id": "tYU1VflCGhk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "#Dando reshape para os dados ficarem 1d, caso necessario\n",
        "#dados_2d = Valores.values.reshape(-1, 1)\n",
        "\n",
        "# Criar o modelo Isolation Forest\n",
        "clf = IsolationForest(contamination=0.1, random_state=42)\n",
        "\n",
        "# Ajustar o modelo aos dados\n",
        "clf.fit(df_subset)\n",
        "\n",
        "# Prever anomalias (outliers)\n",
        "y_pred = clf.predict(df_subset)\n",
        "\n",
        "Forest_df = pd.DataFrame(y_pred, columns=['Forest'])\n",
        "\n",
        "Forest_df['PricePerArea'] = Valores\n",
        "\n",
        "df_sem_outliers = Forest_df.loc[Forest_df['Forest'] == 1]\n",
        "outliers = Forest_df.loc[Forest_df['Forest'] == -1]\n",
        "\n",
        "print('Antes', Valores.count(),'Depois', df_sem_outliers['PricePerArea'].size, 'Outliers:', outliers['PricePerArea'].size)\n"
      ],
      "metadata": {
        "id": "jsgB6KCaprh3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}